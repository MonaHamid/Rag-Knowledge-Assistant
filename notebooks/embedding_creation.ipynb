{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03bd1351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STEP 3: EMBEDDING CREATION & VECTOR DATABASE (Codespaces)\n",
      "======================================================================\n",
      "ü§ñ Loading embedding model: all-MiniLM-L6-v2\n",
      "‚úÖ Model loaded successfully (CPU mode).\n",
      "üìÇ Hybrid chunks found: /workspaces/Rag-Knowledge-Assiatant/notebooks/data/processed/hybrid_chunks.pkl\n",
      "üì¶ Loading hybrid chunks from data/processed/hybrid_chunks.pkl...\n",
      "‚úÖ Loaded 3022 chunks from 150 articles\n",
      "üéØ High priority chunks: 280\n",
      "üîÑ Creating embeddings for 3022 chunks using all-MiniLM-L6-v2 ...\n",
      "   ‚è≥ Batch 1/95 (32 chunks)\n",
      "   ‚è≥ Batch 2/95 (32 chunks)\n",
      "   ‚è≥ Batch 3/95 (32 chunks)\n",
      "   ‚è≥ Batch 4/95 (32 chunks)\n",
      "   ‚è≥ Batch 5/95 (32 chunks)\n",
      "   ‚è≥ Batch 6/95 (32 chunks)\n",
      "   ‚è≥ Batch 7/95 (32 chunks)\n",
      "   ‚è≥ Batch 8/95 (32 chunks)\n",
      "   ‚è≥ Batch 9/95 (32 chunks)\n",
      "   ‚è≥ Batch 10/95 (32 chunks)\n",
      "   ‚è≥ Batch 11/95 (32 chunks)\n",
      "   ‚è≥ Batch 12/95 (32 chunks)\n",
      "   ‚è≥ Batch 13/95 (32 chunks)\n",
      "   ‚è≥ Batch 14/95 (32 chunks)\n",
      "   ‚è≥ Batch 15/95 (32 chunks)\n",
      "   ‚è≥ Batch 16/95 (32 chunks)\n",
      "   ‚è≥ Batch 17/95 (32 chunks)\n",
      "   ‚è≥ Batch 18/95 (32 chunks)\n",
      "   ‚è≥ Batch 19/95 (32 chunks)\n",
      "   ‚è≥ Batch 20/95 (32 chunks)\n",
      "   ‚è≥ Batch 21/95 (32 chunks)\n",
      "   ‚è≥ Batch 22/95 (32 chunks)\n",
      "   ‚è≥ Batch 23/95 (32 chunks)\n",
      "   ‚è≥ Batch 24/95 (32 chunks)\n",
      "   ‚è≥ Batch 25/95 (32 chunks)\n",
      "   ‚è≥ Batch 26/95 (32 chunks)\n",
      "   ‚è≥ Batch 27/95 (32 chunks)\n",
      "   ‚è≥ Batch 28/95 (32 chunks)\n",
      "   ‚è≥ Batch 29/95 (32 chunks)\n",
      "   ‚è≥ Batch 30/95 (32 chunks)\n",
      "   ‚è≥ Batch 31/95 (32 chunks)\n",
      "   ‚è≥ Batch 32/95 (32 chunks)\n",
      "   ‚è≥ Batch 33/95 (32 chunks)\n",
      "   ‚è≥ Batch 34/95 (32 chunks)\n",
      "   ‚è≥ Batch 35/95 (32 chunks)\n",
      "   ‚è≥ Batch 36/95 (32 chunks)\n",
      "   ‚è≥ Batch 37/95 (32 chunks)\n",
      "   ‚è≥ Batch 38/95 (32 chunks)\n",
      "   ‚è≥ Batch 39/95 (32 chunks)\n",
      "   ‚è≥ Batch 40/95 (32 chunks)\n",
      "   ‚è≥ Batch 41/95 (32 chunks)\n",
      "   ‚è≥ Batch 42/95 (32 chunks)\n",
      "   ‚è≥ Batch 43/95 (32 chunks)\n",
      "   ‚è≥ Batch 44/95 (32 chunks)\n",
      "   ‚è≥ Batch 45/95 (32 chunks)\n",
      "   ‚è≥ Batch 46/95 (32 chunks)\n",
      "   ‚è≥ Batch 47/95 (32 chunks)\n",
      "   ‚è≥ Batch 48/95 (32 chunks)\n",
      "   ‚è≥ Batch 49/95 (32 chunks)\n",
      "   ‚è≥ Batch 50/95 (32 chunks)\n",
      "   ‚è≥ Batch 51/95 (32 chunks)\n",
      "   ‚è≥ Batch 52/95 (32 chunks)\n",
      "   ‚è≥ Batch 53/95 (32 chunks)\n",
      "   ‚è≥ Batch 54/95 (32 chunks)\n",
      "   ‚è≥ Batch 55/95 (32 chunks)\n",
      "   ‚è≥ Batch 56/95 (32 chunks)\n",
      "   ‚è≥ Batch 57/95 (32 chunks)\n",
      "   ‚è≥ Batch 58/95 (32 chunks)\n",
      "   ‚è≥ Batch 59/95 (32 chunks)\n",
      "   ‚è≥ Batch 60/95 (32 chunks)\n",
      "   ‚è≥ Batch 61/95 (32 chunks)\n",
      "   ‚è≥ Batch 62/95 (32 chunks)\n",
      "   ‚è≥ Batch 63/95 (32 chunks)\n",
      "   ‚è≥ Batch 64/95 (32 chunks)\n",
      "   ‚è≥ Batch 65/95 (32 chunks)\n",
      "   ‚è≥ Batch 66/95 (32 chunks)\n",
      "   ‚è≥ Batch 67/95 (32 chunks)\n",
      "   ‚è≥ Batch 68/95 (32 chunks)\n",
      "   ‚è≥ Batch 69/95 (32 chunks)\n",
      "   ‚è≥ Batch 70/95 (32 chunks)\n",
      "   ‚è≥ Batch 71/95 (32 chunks)\n",
      "   ‚è≥ Batch 72/95 (32 chunks)\n",
      "   ‚è≥ Batch 73/95 (32 chunks)\n",
      "   ‚è≥ Batch 74/95 (32 chunks)\n",
      "   ‚è≥ Batch 75/95 (32 chunks)\n",
      "   ‚è≥ Batch 76/95 (32 chunks)\n",
      "   ‚è≥ Batch 77/95 (32 chunks)\n",
      "   ‚è≥ Batch 78/95 (32 chunks)\n",
      "   ‚è≥ Batch 79/95 (32 chunks)\n",
      "   ‚è≥ Batch 80/95 (32 chunks)\n",
      "   ‚è≥ Batch 81/95 (32 chunks)\n",
      "   ‚è≥ Batch 82/95 (32 chunks)\n",
      "   ‚è≥ Batch 83/95 (32 chunks)\n",
      "   ‚è≥ Batch 84/95 (32 chunks)\n",
      "   ‚è≥ Batch 85/95 (32 chunks)\n",
      "   ‚è≥ Batch 86/95 (32 chunks)\n",
      "   ‚è≥ Batch 87/95 (32 chunks)\n",
      "   ‚è≥ Batch 88/95 (32 chunks)\n",
      "   ‚è≥ Batch 89/95 (32 chunks)\n",
      "   ‚è≥ Batch 90/95 (32 chunks)\n",
      "   ‚è≥ Batch 91/95 (32 chunks)\n",
      "   ‚è≥ Batch 92/95 (32 chunks)\n",
      "   ‚è≥ Batch 93/95 (32 chunks)\n",
      "   ‚è≥ Batch 94/95 (32 chunks)\n",
      "   ‚è≥ Batch 95/95 (14 chunks)\n",
      "‚úÖ Embeddings created | Shape: (3022, 384)\n",
      "‚è±Ô∏è  Time: 258.0s | Speed: 11.7 chunks/s\n",
      "üîç Creating FAISS index (dimension=384)\n",
      "‚úÖ FAISS index built | Vectors: 3022\n",
      "üíæ Approx memory: 4.43 MB\n",
      "üß™ Testing Retrieval System\n",
      "==================================================\n",
      "\n",
      "üîç Query: What is physics?\n",
      "   1. [MEDIUM] Physics (content)\n",
      "      Score: 0.693\n",
      "      Physics is the scientific study of matter, its fundamental constituents, its motion and behavior thr...\n",
      "\n",
      "   2. [HIGH] Physics (title_beginning)\n",
      "      Score: 0.690\n",
      "      Title: Physics\n",
      "Domain: Science & Engineering\n",
      "\n",
      "Physics is the scientific study of matter, its fundame...\n",
      "\n",
      "   3. [HIGH] Physics (definitions)\n",
      "      Score: 0.623\n",
      "      Key definitions for Physics (Science & Engineering):\n",
      "\n",
      "‚Ä¢ Physics: scientific study of matter\n",
      "...\n",
      "\n",
      "\n",
      "üîç Query: Define photosynthesis\n",
      "   1. [MEDIUM] Biology (content)\n",
      "      Score: 0.620\n",
      "      Photosynthesis has four stages: Light absorption, electron transport, ATP synthesis, and carbon fixa...\n",
      "\n",
      "   2. [MEDIUM] Biology (content)\n",
      "      Score: 0.381\n",
      "      Enzymes act as catalysts‚Äîthey allow a reaction to proceed more rapidly without being consumed by it‚Äî...\n",
      "\n",
      "   3. [MEDIUM] Biology (content)\n",
      "      Score: 0.325\n",
      "      Omnivorous heterotrophs are able to consume at multiple levels. Finally, there are decomposers that ...\n",
      "\n",
      "\n",
      "üîç Query: Explain DNA structure\n",
      "   1. [MEDIUM] Genetics (content)\n",
      "      Score: 0.645\n",
      "      DNA wrapped around these histones are called chromosomes. Viruses sometimes use the similar molecule...\n",
      "\n",
      "   2. [MEDIUM] Genetics (content)\n",
      "      Score: 0.575\n",
      "      The DNA sequence of a gene is used to produce a specific amino acid sequence. This process begins wi...\n",
      "\n",
      "   3. [MEDIUM] Biology (content)\n",
      "      Score: 0.568\n",
      "      A Punnett square can be used to predict the results of a test cross. The chromosome theory of inheri...\n",
      "\n",
      "\n",
      "üîç Query: What is artificial intelligence?\n",
      "   1. [HIGH] Artificial intelligence (definitions)\n",
      "      Score: 0.793\n",
      "      Key definitions for Artificial intelligence (Technology & Computing):\n",
      "\n",
      "‚Ä¢ Artificial intelligence (AI...\n",
      "\n",
      "   2. [HIGH] Artificial intelligence (title_beginning)\n",
      "      Score: 0.788\n",
      "      Title: Artificial intelligence\n",
      "Domain: Technology & Computing\n",
      "\n",
      "Artificial intelligence is intelligen...\n",
      "\n",
      "   3. [MEDIUM] Artificial intelligence (content)\n",
      "      Score: 0.771\n",
      "      Artificial intelligence is intelligence demonstrated by machines, in contrast to the natural intelli...\n",
      "\n",
      "üíæ Saved retrieval system ‚Üí data/processed/retrieval_system_*  (15.79 MB total)\n",
      "\n",
      "‚úÖ STEP 3 COMPLETE! Ready for Step 4: Answer Generation.\n"
     ]
    }
   ],
   "source": [
    "#EMBEDDING CREATION & VECTOR DATABASE (Codespaces Ready)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from collections import Counter\n",
    "import time\n",
    "import os\n",
    "from typing import List, Dict\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Utility: Auto-detect the hybrid chunks file\n",
    "# -------------------------------------------------------------------\n",
    "def get_hybrid_chunk_path(filename=\"hybrid_chunks.pkl\"):\n",
    "    \"\"\"Return path to hybrid chunks file whether in /data/processed or project root.\"\"\"\n",
    "    possible_dirs = [\"data/processed\", \"data\", \".\"]\n",
    "    for d in possible_dirs:\n",
    "        p = Path(d) / filename\n",
    "        if p.exists():\n",
    "            print(f\"üìÇ Hybrid chunks found: {p.resolve()}\")\n",
    "            return str(p)\n",
    "    raise FileNotFoundError(f\"‚ùå hybrid_chunks.pkl not found in {possible_dirs}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Embedding + FAISS Creator\n",
    "# -------------------------------------------------------------------\n",
    "class EmbeddingCreator:\n",
    "    \"\"\"Create embeddings and FAISS index for hybrid chunks\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        print(f\"ü§ñ Loading embedding model: {model_name}\")\n",
    "        try:\n",
    "            self.model = SentenceTransformer(model_name, device=\"cpu\")\n",
    "            self.model_name = model_name\n",
    "            print(\"‚úÖ Model loaded successfully (CPU mode).\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load {model_name}: {e}\")\n",
    "            print(\"üí° Using fallback model paraphrase-MiniLM-L6-v2\")\n",
    "            try:\n",
    "                self.model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\", device=\"cpu\")\n",
    "                self.model_name = \"paraphrase-MiniLM-L6-v2\"\n",
    "                print(\"‚úÖ Fallback model loaded.\")\n",
    "            except Exception as e2:\n",
    "                print(f\"‚ùå Both models failed: {e2}\")\n",
    "                self.model = None\n",
    "                self.model_name = \"tfidf_fallback\"\n",
    "\n",
    "        self.chunks = []\n",
    "        self.embeddings = None\n",
    "        self.index = None\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 1Ô∏è‚É£ Load hybrid chunks\n",
    "    # -----------------------------------------------------------\n",
    "    def load_hybrid_chunks(self, filename=None) -> Dict:\n",
    "        filename = filename or get_hybrid_chunk_path()\n",
    "        print(f\"üì¶ Loading hybrid chunks from {filename}...\")\n",
    "        with open(filename, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        self.chunks = data[\"chunks\"]\n",
    "        stats = data.get(\"stats\", {})\n",
    "        print(f\"‚úÖ Loaded {len(self.chunks)} chunks from {stats.get('total_articles', '?')} articles\")\n",
    "        print(f\"üéØ High priority chunks: {stats.get('priority_distribution', {}).get('HIGH', 0)}\")\n",
    "        return data\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 2Ô∏è‚É£ Create embeddings\n",
    "    # -----------------------------------------------------------\n",
    "    def create_embeddings(self, batch_size: int = 32) -> np.ndarray:\n",
    "        if not self.chunks:\n",
    "            raise ValueError(\"‚ùå No chunks loaded. Please run load_hybrid_chunks() first.\")\n",
    "\n",
    "        texts = [c[\"text\"] for c in self.chunks]\n",
    "        print(f\"üîÑ Creating embeddings for {len(texts)} chunks using {self.model_name} ...\")\n",
    "\n",
    "        if self.model is None:\n",
    "            return self._create_tfidf_embeddings(texts)\n",
    "\n",
    "        embeddings = []\n",
    "        total_batches = (len(texts) + batch_size - 1) // batch_size\n",
    "        start = time.time()\n",
    "\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i : i + batch_size]\n",
    "            batch_id = i // batch_size + 1\n",
    "            print(f\"   ‚è≥ Batch {batch_id}/{total_batches} ({len(batch_texts)} chunks)\")\n",
    "            batch_embeddings = self.model.encode(batch_texts, show_progress_bar=False)\n",
    "            embeddings.append(batch_embeddings)\n",
    "\n",
    "        self.embeddings = np.vstack(embeddings).astype(\"float32\")\n",
    "        elapsed = time.time() - start\n",
    "\n",
    "        print(f\"‚úÖ Embeddings created | Shape: {self.embeddings.shape}\")\n",
    "        print(f\"‚è±Ô∏è  Time: {elapsed:.1f}s | Speed: {len(texts)/elapsed:.1f} chunks/s\")\n",
    "        return self.embeddings\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 3Ô∏è‚É£ TF-IDF Fallback (no transformer)\n",
    "    # -----------------------------------------------------------\n",
    "    def _create_tfidf_embeddings(self, texts: List[str]) -> np.ndarray:\n",
    "        print(\"‚ö†Ô∏è  Using TF-IDF fallback embeddings\")\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "        vectorizer = TfidfVectorizer(max_features=1000, stop_words=\"english\")\n",
    "        tfidf = vectorizer.fit_transform(texts)\n",
    "        self.embeddings = tfidf.toarray().astype(\"float32\")\n",
    "        print(f\"‚úÖ TF-IDF embeddings created: {self.embeddings.shape}\")\n",
    "        return self.embeddings\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 4Ô∏è‚É£ Create FAISS index\n",
    "    # -----------------------------------------------------------\n",
    "    def create_vector_index(self) -> faiss.Index:\n",
    "        if self.embeddings is None:\n",
    "            raise ValueError(\"‚ùå No embeddings found. Run create_embeddings() first.\")\n",
    "\n",
    "        dim = self.embeddings.shape[1]\n",
    "        print(f\"üîç Creating FAISS index (dimension={dim})\")\n",
    "\n",
    "        self.index = faiss.IndexFlatIP(dim)\n",
    "        emb_norm = self.embeddings.copy()\n",
    "        faiss.normalize_L2(emb_norm)\n",
    "        self.index.add(emb_norm)\n",
    "        print(f\"‚úÖ FAISS index built | Vectors: {self.index.ntotal}\")\n",
    "        print(f\"üíæ Approx memory: {(self.index.ntotal * dim * 4) / 1024 / 1024:.2f} MB\")\n",
    "        return self.index\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 5Ô∏è‚É£ Test retrieval with sample queries\n",
    "    # -----------------------------------------------------------\n",
    "    def test_retrieval(self, queries: List[str], k: int = 5):\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"‚ùå No FAISS index. Run create_vector_index() first.\")\n",
    "\n",
    "        print(\"üß™ Testing Retrieval System\")\n",
    "        print(\"=\" * 50)\n",
    "        for query in queries:\n",
    "            print(f\"\\nüîç Query: {query}\")\n",
    "            q_emb = self.model.encode([query])\n",
    "            faiss.normalize_L2(q_emb)\n",
    "            scores, indices = self.index.search(q_emb, k)\n",
    "            for rank, (score, idx) in enumerate(zip(scores[0], indices[0])):\n",
    "                if idx >= len(self.chunks): \n",
    "                    continue\n",
    "                ch = self.chunks[idx]\n",
    "                print(f\"   {rank+1}. [{ch['priority']}] {ch['metadata']['title']} ({ch['chunk_type']})\")\n",
    "                print(f\"      Score: {score:.3f}\")\n",
    "                print(f\"      {ch['text'][:100]}...\\n\")\n",
    "\n",
    "    # -----------------------------------------------------------\n",
    "    # 6Ô∏è‚É£ Save everything\n",
    "    # -----------------------------------------------------------\n",
    "    def save_retrieval_system(self, out_prefix=\"data/processed/retrieval_system\"):\n",
    "        Path(\"data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        emb_file = f\"{out_prefix}_embeddings.npy\"\n",
    "        index_file = f\"{out_prefix}_index.faiss\"\n",
    "        meta_file = f\"{out_prefix}_metadata.pkl\"\n",
    "\n",
    "        np.save(emb_file, self.embeddings)\n",
    "        faiss.write_index(self.index, index_file)\n",
    "\n",
    "        metadata = {\n",
    "            \"chunks\": self.chunks,\n",
    "            \"model_name\": self.model_name,\n",
    "            \"embedding_dimension\": self.embeddings.shape[1],\n",
    "            \"total_chunks\": len(self.chunks),\n",
    "        }\n",
    "        with open(meta_file, \"wb\") as f:\n",
    "            pickle.dump(metadata, f)\n",
    "\n",
    "        total_mb = sum(os.path.getsize(f) for f in [emb_file, index_file, meta_file]) / 1024 / 1024\n",
    "        print(f\"üíæ Saved retrieval system ‚Üí {out_prefix}_*  ({total_mb:.2f} MB total)\")\n",
    "        return {\"embeddings\": emb_file, \"index\": index_file, \"metadata\": meta_file}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Runner for Codespaces\n",
    "# -------------------------------------------------------------------\n",
    "def run_embedding_creation():\n",
    "    print(\"üöÄ STEP 3: EMBEDDING CREATION & VECTOR DATABASE (Codespaces)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    creator = EmbeddingCreator()\n",
    "    creator.load_hybrid_chunks()\n",
    "    creator.create_embeddings(batch_size=32)\n",
    "    creator.create_vector_index()\n",
    "\n",
    "    # Simple sanity test queries\n",
    "    sample_queries = [\n",
    "        \"What is physics?\",\n",
    "        \"Define photosynthesis\",\n",
    "        \"Explain DNA structure\",\n",
    "        \"What is artificial intelligence?\"\n",
    "    ]\n",
    "    creator.test_retrieval(sample_queries, k=3)\n",
    "    creator.save_retrieval_system()\n",
    "\n",
    "    print(\"\\n‚úÖ STEP 3 COMPLETE! Ready for Step 4: Answer Generation.\")\n",
    "    return creator\n",
    "\n",
    "# Execute when running directly\n",
    "if __name__ == \"__main__\":\n",
    "    creator = run_embedding_creation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
